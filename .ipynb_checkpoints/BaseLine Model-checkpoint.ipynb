{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('team_data/all_games_train.pkl', 'rb') as fp:\n",
    "    all_games_train =  pickle.load(fp)\n",
    "    \n",
    "with open('team_data/all_games_test.pkl', 'rb') as fp:\n",
    "    all_games_test =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def data_to_vector(data, team_names):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for team in data:\n",
    "        for game in data[team]:\n",
    "            #extract features\n",
    "            feature = [0] * 60\n",
    "            #processing specific case for portland\n",
    "            opp = game[0][0]\n",
    "            if opp == 'portland':\n",
    "                opp = 'portland trail'\n",
    "            if opp[-1] == '*':\n",
    "                opp = opp[:-1].strip()\n",
    "            #computing feature vector\n",
    "            if data[team][0][-1] == '1':\n",
    "                feature[team_names.index(team)] = 1\n",
    "                feature[30 + team_names.index(opp)] = 1\n",
    "            else:\n",
    "                feature[team_names.index(opp)] = 1\n",
    "                feature[30 + team_names.index(team)] = 1\n",
    "            features.append(feature)\n",
    "            #extract labels\n",
    "            labels.append(game[1])\n",
    "    return (np.array(features), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names = list(all_games_train.keys())\n",
    "train_features, train_labels = data_to_vector(all_games_train, team_names)\n",
    "test_features, test_labels = data_to_vector(all_games_test, team_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "def cal_accuracy(train_features, train_labels, test_features, test_labels):\n",
    "    svm = LinearSVC(loss='hinge')\n",
    "    svm.fit(train_features, train_labels)\n",
    "    y_pred = svm.predict(test_features)\n",
    "    return accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.612964180085442"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_accuracy(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5531547814656589"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(train_features, train_labels)\n",
    "y_pred = clf.predict(test_features)\n",
    "accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "#Model3 Fullly Connected Neural Network\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \"\"\"CIFAR-10 image dataset.\"\"\"\n",
    "    def __init__(self, X, y, transformations=None):\n",
    "        self.len = len(X)           \n",
    "        self.x_data = torch.from_numpy(X).float()\n",
    "        self.y_data = torch.from_numpy(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.fc1 as the variable name for your first fully connected layer\n",
    "        (2) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(FeedForwardNN, self).__init__()\n",
    " \n",
    "        self.fc1 = nn.Linear(60, 12)\n",
    "        self.fc2 = nn.Linear(12, 2)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.fc1(x))\n",
    "        out = F.sigmoid(self.fc2(out))\n",
    "\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "clf_nn = FeedForwardNN()\n",
    "\n",
    "train_features = train_features.astype(int)\n",
    "train_labels = train_labels.astype(int)\n",
    "dataset = Dataset(train_features, train_labels)\n",
    "\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = 100,\n",
    "                          shuffle = True)\n",
    "\n",
    "\n",
    "test_features = test_features.astype(int)\n",
    "test_labels = test_labels.astype(int)\n",
    "dataset = Dataset(test_features, test_labels)\n",
    "test_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = 100,\n",
    "                        shuffle = True)\n",
    "\n",
    "optimizer = optim.SGD(clf_nn.parameters(), lr = 0.001, momentum = 0.9, weight_decay = 5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "max_epochs = 1000\n",
    "\n",
    "accuracy = np.zeros((max_epochs))\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        # Get inputs and labels from data loader \n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # Feed the input data into the network \n",
    "        y_pred = clf_nn(inputs)\n",
    "\n",
    "        # Calculate the loss using predicted labels and ground truth labels\n",
    "\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        #print(\"epoch: \", epoch, \"loss: \", loss.data[0])\n",
    "\n",
    "        # zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backpropogates to compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # updates the weghts\n",
    "        optimizer.step()\n",
    "\n",
    "        # convert predicted laels into numpy\n",
    "        y_pred_np = y_pred.data.numpy()\n",
    "\n",
    "        # calculate the training accuracy of the current model\n",
    "\n",
    "        label_np = labels.data.numpy().reshape(len(labels),1)\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total_size = 0\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "    # Get inputs and labels from data loader \n",
    "    inputs, labels = data\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    # Feed the input data into the network \n",
    "    y_pred = clf_nn(inputs)\n",
    "\n",
    "    # convert predicted laels into numpy\n",
    "    y_pred_np = y_pred.data.numpy()\n",
    "    \n",
    "    # calculate the training accuracy of the current model\n",
    "    pred_np = y_pred_np  \n",
    "    label_np = labels.data.numpy().reshape(len(labels),1)\n",
    "\n",
    "\n",
    "    for j in range(y_pred_np.shape[0]):\n",
    "        if np.argmax(pred_np[j,:]) == label_np[j,:]:\n",
    "            correct += 1\n",
    "    total_size += len(labels)\n",
    "test_accuracy = float(correct) / float(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444298389746961"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
