{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_games_train.pkl', 'rb') as fp:\n",
    "    all_games_train =  pickle.load(fp)\n",
    "    \n",
    "with open('all_games_test.pkl', 'rb') as fp:\n",
    "    all_games_test =  pickle.load(fp)\n",
    "    \n",
    "with open('train_total.pkl', 'rb') as fp:\n",
    "    train_total =  pickle.load(fp)\n",
    "    \n",
    "with open('test_total.pkl', 'rb') as fp:\n",
    "    test_total =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def advanced_representation(all_games, total):\n",
    "    X = []\n",
    "    y = []\n",
    "    for team_name in all_games_train:\n",
    "        for game in all_games_train[team_name]:\n",
    "            opp_name = game[0][0]\n",
    "            if opp_name == 'portland':\n",
    "                opp_name = 'portland trail'\n",
    "            if opp_name[-1] == '*':\n",
    "                opp_name = opp_name[:-1].strip()\n",
    "            year = game[2]\n",
    "            label = int(game[1])\n",
    "            past_games = game[0][1:-1]\n",
    "            past_games = np.asarray(past_games)\n",
    "            past_games = list(map(eval, past_games))\n",
    "            location = list(game[0][-1])\n",
    "            location = np.asarray(location)\n",
    "            location = list(map(eval, location))\n",
    "            active_index = [1,2,3,4,5,6,7,8,9,10,12,13,15,16,18,19,20,21,23]\n",
    "            data1 = np.asarray(train_total[team_name][year])\n",
    "            data1 = data1[active_index]\n",
    "            data1 = list(map(eval, data1))\n",
    "            data2 = np.asarray(train_total[opp_name][year])\n",
    "            data2 = data2[active_index]\n",
    "            data2 = list(map(eval, data2))\n",
    "            data1 = np.asarray(data1)\n",
    "            data2 = np.asarray(data2)\n",
    "            diff = list((data1>data2)*1)\n",
    "            feature = diff + past_games + location\n",
    "            X.append(feature)\n",
    "            y.append(label)\n",
    "    return (np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_train, adv_train_label = advanced_representation(all_games_train, train_total)\n",
    "adv_test, adv_test_label = advanced_representation(all_games_test, test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "def cal_accuracy(adv_train, adv_train_label, adv_test, adv_test_label):\n",
    "    clf = Perceptron()\n",
    "    clf.fit(adv_train, adv_train_label)\n",
    "    y_pred = clf.predict(adv_test)\n",
    "    return accuracy_score(adv_test_label, y_pred)\n",
    "\n",
    "cal_accuracy(adv_train, adv_train_label, adv_test, adv_test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6957771935589878"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2 SVM with kernel function\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "def cal_accuracy(adv_train, adv_train_label, adv_test, adv_test_label):\n",
    "    svm = SVC(gamma = 'scale', kernel = 'poly')\n",
    "    svm.fit(adv_train, adv_train_label)\n",
    "    y_pred = svm.predict(adv_test)\n",
    "    return accuracy_score(adv_test_label, y_pred)\n",
    "cal_accuracy(adv_train, adv_train_label, adv_test, adv_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12172, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model3 Fullly Connected Neural Network\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \"\"\"CIFAR-10 image dataset.\"\"\"\n",
    "    def __init__(self, X, y, transformations=None):\n",
    "        self.len = len(X)           \n",
    "        self.x_data = torch.from_numpy(X).float()\n",
    "        self.y_data = torch.from_numpy(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "    \n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.fc1 as the variable name for your first fully connected layer\n",
    "        (2) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(FeedForwardNN, self).__init__()\n",
    " \n",
    "        self.fc1 = nn.Linear(25, 12)\n",
    "        self.fc2 = nn.Linear(12, 2)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.fc1(x))\n",
    "        out = F.sigmoid(self.fc2(out))\n",
    "\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "clf_nn = FeedForwardNN()\n",
    "\n",
    "\n",
    "\n",
    "dataset = Dataset(adv_train, adv_train_label)\n",
    "\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = 100,\n",
    "                          shuffle = True)\n",
    "\n",
    "\n",
    "dataset = Dataset(adv_test, adv_test_label)\n",
    "test_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = 100,\n",
    "                        shuffle = True)\n",
    "\n",
    "optimizer = optim.SGD(clf_nn.parameters(), lr = 0.001, momentum = 0.9, weight_decay = 5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "max_epochs = 1000\n",
    "\n",
    "accuracy = np.zeros((max_epochs))\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        # Get inputs and labels from data loader \n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # Feed the input data into the network \n",
    "        y_pred = clf_nn(inputs)\n",
    "\n",
    "        # Calculate the loss using predicted labels and ground truth labels\n",
    "\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        #print(\"epoch: \", epoch, \"loss: \", loss.data[0])\n",
    "\n",
    "        # zero gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backpropogates to compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # updates the weghts\n",
    "        optimizer.step()\n",
    "\n",
    "        # convert predicted laels into numpy\n",
    "        y_pred_np = y_pred.data.numpy()\n",
    "\n",
    "        # calculate the training accuracy of the current model\n",
    "\n",
    "        label_np = labels.data.numpy().reshape(len(labels),1)\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total_size = 0\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "\n",
    "    # Get inputs and labels from data loader \n",
    "    inputs, labels = data\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "    # Feed the input data into the network \n",
    "    y_pred = clf_nn(inputs)\n",
    "\n",
    "    # convert predicted laels into numpy\n",
    "    y_pred_np = y_pred.data.numpy()\n",
    "\n",
    "    # calculate the training accuracy of the current model\n",
    "    pred_np = y_pred_np  \n",
    "    label_np = labels.data.numpy().reshape(len(labels),1)\n",
    "\n",
    "\n",
    "    for j in range(y_pred_np.shape[0]):\n",
    "        if np.argmax(pred_np[j,:]) == label_np[j,:]:\n",
    "            correct += 1\n",
    "    total_size += len(labels)\n",
    "test_accuracy = float(correct) / float(total_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6683371672691423"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
